{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppxscal/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('bigscience/P3', 'cos_e_v1.11_aligned_with_common_sense')\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained('sshleifer/distilbart-cnn-12-6')\n",
    "model_continuos = BartForConditionalGeneration.from_pretrained('sshleifer/distilbart-cnn-12-6')\n",
    "model_projected = BartForConditionalGeneration.from_pretrained('sshleifer/distilbart-cnn-12-6')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_continuos.to(device)\n",
    "model_projected.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt basis shape: torch.Size([4, 43, 1024])\n"
     ]
    }
   ],
   "source": [
    "#lets define our prompt basis\n",
    "\n",
    "#input embeddings shape: torch.Size([8, 82, 1024])\n",
    "# combined embeddings shape: torch.Size([8, 102, 1024])\n",
    "# outputs shape: torch.Size([8, 26, 50264])\n",
    "# labels shape: torch.Size([8, 26])\n",
    "# labels pretokenized: ['\\nwebmath is designed to help you solve', '\\nbums are well known to take up residence under bridges.', '\\nthis word is most relavant', '\\nst.paul is a county in minnesota', '\\nif you need speed, corvette is the answer.', '\\nwashington is the only place in the list that has pacific beaches', '\\na big fountain was the center piece of the renovation, it had all been paid for by a grant to the city', '\\nbeing ambitious means they will work hard to be good.']\n",
    "\n",
    "prompt_list = [\n",
    "    'When you see the following question, I would like you to answer it correctly', # ~13 tokens \n",
    "    'Produce an executable artifact of type X that will answer the question, and then execute it',\n",
    "    'When I ask you a question, generate three additional questions that would help you give a more accurate answer. When you then answered the three questions, combine the answers to produce the final answers to my original question',\n",
    "    'Generate a set of facts that are contained in the output. The set of facts should be inserted in a specific point in the output to answer the question',\n",
    "]\n",
    "\n",
    "basis = tokenizer(prompt_list, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "print(f'prompt basis shape: {model_projected.model.shared(basis.input_ids).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FFNN architecture\n",
    "class LearnWeights(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LearnWeights, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'combined_soft_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ppxscal/Projects/nlp/nlp_project/experiment_4.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiment_4.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m continuous_input_embeddings \u001b[39m=\u001b[39m model_continuos\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared(input_ids)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiment_4.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m projected_input_embeddings \u001b[39m=\u001b[39m model_projected\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared(input_ids)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiment_4.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m soft_prompt_batch \u001b[39m=\u001b[39m soft_prompt\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mrepeat(combined_soft_embeddings\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiment_4.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m projected_prompt_batch \u001b[39m=\u001b[39m learn_weights(soft_prompt_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiment_4.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m combined_soft_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([soft_prompt_batch, combined_soft_embeddings], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_soft_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the soft prompt\n",
    "L = 20\n",
    "d = model_projected.model.shared.embedding_dim\n",
    "soft_prompt = torch.randn(L, d).to(device)\n",
    "soft_prompt = torch.nn.Parameter(soft_prompt)\n",
    "optimizer_continuous = AdamW([soft_prompt])\n",
    "\n",
    "#Define the projected prompt\n",
    "input_dim = d  \n",
    "hidden_dim = 64\n",
    "output_dim = len(prompt_list)\n",
    "learn_weights = LearnWeights(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer_projected = AdamW(learn_weights.parameters())\n",
    "\n",
    "# Training parameters\n",
    "epochs = 1\n",
    "batch_size = 4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('starting training')\n",
    "\n",
    "# Training loop\n",
    "continuous_losses = []\n",
    "projected_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss_continuous = 0\n",
    "    epoch_loss_projected = 0\n",
    "    for i in range(0, len(train_dataset) - 9000, batch_size):\n",
    "        batch = train_dataset[i:i+batch_size]\n",
    "        input_ids = tokenizer(batch['inputs_pretokenized'], return_tensors='pt', padding=True, truncation=True).input_ids.to(device)\n",
    "        labels = tokenizer(batch['targets_pretokenized'], return_tensors='pt', padding=True, truncation=True).input_ids.to(device)\n",
    "\n",
    "        # Get the input embeddings\n",
    "        continuous_input_embeddings = model_continuos.model.shared(input_ids)\n",
    "        projected_input_embeddings = model_projected.model.shared(input_ids)\n",
    "\n",
    "        soft_prompt_batch = soft_prompt.unsqueeze(0).repeat(combined_soft_embeddings.size(0), 1, 1).to(device)\n",
    "        projected_prompt_batch = learn_weights(soft_prompt_batch)\n",
    "        \n",
    "        combined_soft_embeddings = torch.cat([soft_prompt_batch, combined_soft_embeddings], dim=1)\n",
    "        combined_projected_embeddings = torch.cat([projected_prompt_batch, combined_projected_embeddings], dim=1)\n",
    "\n",
    "        # Pass the combined embeddings through the model\n",
    "        outputs_continous = model_continuos(inputs_embeds=combined_soft_embeddings, labels=labels)\n",
    "        outputs_projected = model_projected(inputs_embeds=combined_projected_embeddings, labels=labels)\n",
    "        # print(f'input embeddings shape: {input_embeddings.shape}')\n",
    "        # print(f'combined embeddings shape: {combined_embeddings.shape}')\n",
    "        # print(f'outputs shape: {outputs.logits.shape}')\n",
    "        # print(f'labels shape: {labels.shape}')\n",
    "        # # print(f'labels: {labels}')\n",
    "        # print(f'labels pretokenized: {batch[\"targets_pretokenized\"]}')\n",
    "        loss_continuous = outputs_continous.loss\n",
    "        epoch_loss_continuous += loss_continuous.item()\n",
    "        \n",
    "        loss_projected = outputs_projected.loss\n",
    "        epoch_loss_projected += loss_projected.item()\n",
    "        \n",
    "        loss_continuous.backward()\n",
    "        loss_projected.backward()\n",
    "        \n",
    "        optimizer_projected.step()\n",
    "        optimizer_projected.zero_grad()\n",
    "        print(f'\\r complete from this epoch {i}/{len(train_dataset)}', end='')\n",
    "        print(f'\\r loss continous: {loss_continuous.item()}', end='')\n",
    "        print(f'\\r loss projected: {loss_projected.item()}', end='')\n",
    "\n",
    "\n",
    "    epoch_loss_continuous /= len(train_dataset)\n",
    "    epoch_loss_projected /= len(train_dataset)\n",
    "    \n",
    "    continuous_losses.append(epoch_loss_continuous)\n",
    "    projected_losses.append(epoch_loss_projected)\n",
    "    \n",
    "    print(f'\\r Epoch {epoch+1}/{epochs} complete. Loss: {epoch_loss_continuous}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame with the loss values\n",
    "data = {\n",
    "    'Epoch': list(range(1, epochs + 1)) * 2,\n",
    "    'Loss': continuous_losses + projected_losses,\n",
    "    'Model': ['Continuous'] * epochs + ['Projected'] * epochs\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='Epoch', y='Loss', hue='Model')\n",
    "plt.title('Loss per Epoch for Continuous and Projected Models')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
