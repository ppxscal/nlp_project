{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normalize(vector):\n",
    "    norm = np.linalg.norm(vector)\n",
    "    if norm == 0: \n",
    "        return vector\n",
    "    return vector / norm\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('bigscience/P3', 'ai2_arc_ARC_Challenge_pick_the_most_correct_option')\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# Initialize the tokenizer and models (one or continuous prompting and other for projected prompting\n",
    "model_projected = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_projected.to(device)\n",
    "\n",
    "# Define the prompt basis\n",
    "prompt_list = [\n",
    "    \"Generate a flowchart to visually represent the logic needed to answer the question\",\n",
    "    \"Write pseudocode for an algorithm that could determine the answer\", \n",
    "    \"Imagine you are explaining the answer to a 5-year-old. Use simple words and analogies.\",\n",
    "    \"Summarize the key insights needed to answer in a short poem\",\n",
    "    \"Draw a concept map connecting all ideas relevant to the question\",\n",
    "    \"List assumptions you must make to provide an answer. What if those assumptions were different?\",\n",
    "    \"Compare and contrast multiple ways to approach the question\", \n",
    "    \"Translate the essence of the question into visual art and describe your interpretation\",\n",
    "    \"Act out an exaggerated skit to depict the logic behind the answer\",\n",
    "    \"Design a decision tree leading to the final answer\",\n",
    "    \"Develop a graphic organizer highlighting relationships between key ideas\",\n",
    "    \"Frame the question from different philosophical perspectives and give each perspective's answer\", \n",
    "    \"Outline an experiment that could empirically validate the answer\",\n",
    "    \"Write a song conveying the concepts needed to respond accurately\",\n",
    "    \"Create a metaphor relating the question to a seemingly unrelated domain\",\n",
    "    \"Prototype a computer program to compute the answer algorithmically\"\n",
    "]\n",
    "\n",
    "print(f'tokenizing prompts')\n",
    "print(f'prompt list length {len(prompt_list)}')\n",
    "\n",
    "basis = tokenizer(prompt_list, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "basis = model_projected.model.shared(basis.input_ids)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['inputs_pretokenized'], truncation=True, padding='max_length')\n",
    "\n",
    "# Apply the function to the dataset\n",
    "print('tokenzing dataset')\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the weight prediction model\n",
    "class LearnWeights(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.5):\n",
    "        super(LearnWeights, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 512)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.layer2 = nn.Linear(512, 128)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.layer3 = nn.Linear(128, 64)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.output_layer = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = x.mean(dim=1, keepdim=True)  # Compute the mean across the token dimension and batch dimension\n",
    "        return normalize(x.squeeze(1).mean(dim=0))\n",
    "\n",
    "\n",
    "# Define the projected prompt\n",
    "input_dim = 1024\n",
    "\n",
    "output_dim = len(prompt_list)\n",
    "learn_weights = LearnWeights(input_dim, output_dim).to(device)\n",
    "optimizer_projected = AdamW(learn_weights.parameters())\n",
    "\n",
    "# Training parameters\n",
    "epochs = 5\n",
    "batch_size = 4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/20, Batch 0/1119\n",
      "Batch Indices: [1040, 1041]\n",
      "Loss: 11.13280200958252\n",
      "Weights for this question: tensor([-0.1114,  0.1205,  0.0740,  0.0724,  0.0822, -0.0917,  0.0089, -0.0204,\n",
      "         0.1065, -0.0713, -0.0015, -0.0520, -0.0213,  0.0313, -0.1114, -0.0404],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>) question: ['Pick the most correct option to answer the following question.\\n\\nScientists use models that show the features of an atom. A scientist should use a model that\\n\\nOptions:\\n\\n- A: was the first to be developed\\n\\n- B: was most recently developed\\n\\n- C: shows the arrangement most clearly\\n\\n- D: shows the details needed for a specific purpose\\n ', 'Pick the most correct option to answer the following question.\\n\\nA student is measuring the boiling point of a salt and water mixture. He takes one temperature measurement of 105°C. Which is the best way to ensure the results are valid?\\n\\nOptions:\\n\\n- A: repeat the investigation\\n\\n- B: change the volume of water\\n\\n- C: add more salt to the mixture\\n\\n- D: do the investigation without salt\\n ']\n",
      "\n",
      "Epoch 1/20, Batch 200/1119\n",
      "Batch Indices: [1280, 1281]\n",
      "Loss: 10.862113952636719\n",
      "Weights for this question: tensor([-0.2086,  0.1231,  0.0555,  0.0547,  0.1024, -0.1595, -0.0261, -0.0700,\n",
      "         0.1395, -0.1063, -0.0617, -0.0709, -0.0349,  0.0150, -0.0841, -0.0381],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>) question: ['Pick the most correct option to answer the following question.\\n\\nWhich characteristic property indicates that igneous rock cools slowly?\\n\\nOptions:\\n\\n- A: mineral composition\\n\\n- B: hardness\\n\\n- C: density\\n\\n- D: crystal size\\n ', 'Pick the most correct option to answer the following question.\\n\\nWhat unit do scientists use to measure the distance between stars?\\n\\nOptions:\\n\\n- A: light-year\\n\\n- B: angstrom unit\\n\\n- C: astronomical unit\\n\\n- D: apparent magnitude\\n ']\n",
      "\n",
      "Epoch 1/20, Batch 400/1119\n",
      "Batch Indices: [32, 33]\n",
      "Loss: 10.321088790893555\n",
      "Weights for this question: tensor([-0.2127,  0.1061,  0.0955,  0.0662,  0.0821, -0.1540, -0.0342, -0.1486,\n",
      "         0.1335, -0.0840, -0.0692, -0.0685, -0.0319,  0.0388, -0.1005, -0.0229],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>) question: ['Pick the most correct option to answer the following question.\\n\\nA chemical property of a mineral is evident if the mineral\\n\\nOptions:\\n\\n- A: breaks easily when struck with a hammer\\n\\n- B: bubbles when acid is placed on it\\n\\n- C: is easily scratched by a fingernail\\n\\n- D: reflects light from its surface\\n ', \"Pick the most correct option to answer the following question.\\n\\nOne evening as it is getting dark, Alex sits on the front porch and watches the sun slowly disappear behind the neighbor's house across the street. Which explains this observation?\\n\\nOptions:\\n\\n- A: The sun's light is reflected by the clouds.\\n\\n- B: The sun's light is refracted by the atmosphere.\\n\\n- C: The sun moves from west to east each day.\\n\\n- D: The sun appears to move due to Earth's rotation.\\n \"]\n",
      "\n",
      "Epoch 1/20, Batch 600/1119\n",
      "Batch Indices: [1386, 1387]\n",
      "Loss: 11.105558395385742\n",
      "Weights for this question: tensor([-0.4847,  0.2886,  0.0926, -0.1953,  0.0103, -0.2567,  0.0146, -0.5155,\n",
      "         0.3070,  0.0657, -0.2174, -0.1673, -0.1633, -0.1998, -0.2785, -0.0220],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>) question: ['Pick the most correct option to answer the following question.\\n\\nSome students used a hot plate to heat 1 L of water from 20°C to the boiling point of water. The students recorded the temperature of the water each minute until it began to boil. Which of the following provides the most appropriate way to represent the data?\\n\\nOptions:\\n\\n- A: a bar graph with temperature on the y-axis and time on the x-axis\\n\\n- B: a bar graph with time on the y-axis and temperature on the x-axis\\n\\n- C: a line graph with temperature on the y-axis and time on the x-axis\\n\\n- D: a line graph with time on the y-axis and temperature on the x-axis\\n ', 'Pick the most correct option to answer the following question.\\n\\nWhich transition is most responsible for gaps in the fossil record?\\n\\nOptions:\\n\\n- A: metamorphic rock to igneous rock\\n\\n- B: igneous rock to metamorphic rock\\n\\n- C: metamorphic rock to sedimentary rock\\n\\n- D: sedimentary rock to metamorphic rock\\n ']\n",
      "\n",
      "Epoch 1/20, Batch 800/1119\n",
      "Batch Indices: [1600, 1601]\n",
      "Loss: 11.194292068481445\n",
      "Weights for this question: tensor([-0.3649,  0.3628, -0.0141, -0.2792, -0.0169, -0.0783,  0.0703, -0.3783,\n",
      "         0.2838, -0.0187, -0.1657, -0.1623, -0.2100, -0.2795, -0.2858, -0.1155],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>) question: ['Pick the most correct option to answer the following question.\\n\\nMost of the volume of the universe is found in the space between galaxies. Objects found in the regions between galaxies are most likely to be closest in size to which of these?\\n\\nOptions:\\n\\n- A: a dust particle\\n\\n- B: an asteroid\\n\\n- C: a planet\\n\\n- D: a star\\n ', 'Pick the most correct option to answer the following question.\\n\\nWhich of the following statements best explains why the tilt of Earth on its axis causes summer to be warmer than winter in the Northern Hemisphere?\\n\\nOptions:\\n\\n- A: The warm ocean currents flow from the tropics to the Northern Hemisphere in the summer.\\n\\n- B: The rays of the Sun strike the Northern Hemisphere more directly in the summer.\\n\\n- C: The greenhouse effect increases in the Northern Hemisphere in the summer.\\n\\n- D: The Northern Hemisphere is closer to the Sun in the summer.\\n ']\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ppxscal/Projects/nlp/nlp_project/experiments/experiment_17/experiment_17.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiments/experiment_17/experiment_17.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m outputs_projected \u001b[39m=\u001b[39m model_projected(inputs_embeds\u001b[39m=\u001b[39mcombined_projected_embeddings, labels\u001b[39m=\u001b[39mlabels)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiments/experiment_17/experiment_17.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m loss_projected \u001b[39m=\u001b[39m outputs_projected\u001b[39m.\u001b[39mloss\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiments/experiment_17/experiment_17.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m epoch_loss_projected \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_projected\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiments/experiment_17/experiment_17.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m optimizer_projected\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ppxscal/Projects/nlp/nlp_project/experiments/experiment_17/experiment_17.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m loss_projected\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 20\n",
    "batch_size = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "# Training loop\n",
    "projected_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "shapes = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss_projected = 0\n",
    "    epoch_loss_validation = 0\n",
    "    for _ in range(0, len(train_dataset), batch_size):\n",
    "        i = random.randint(0, len(train_dataset) - batch_size + 1 )\n",
    "        batch = train_dataset[i:i+batch_size]\n",
    "        if len(batch['inputs_pretokenized']) != batch_size:\n",
    "          continue\n",
    "        input_ids = tokenizer(batch['inputs_pretokenized'], return_tensors='pt', padding=True, truncation=True).input_ids.to(device)\n",
    "        labels = tokenizer(batch['targets_pretokenized'], return_tensors='pt', padding=True, truncation=True).input_ids.to(device)\n",
    "\n",
    "        # Get the prompt input embeddings - same if continuous or projected\n",
    "        input_embeddings = model_projected.model.shared(input_ids)\n",
    "        padding_size = max(0, 100 - input_embeddings.shape[1])\n",
    "        input_embeddings = F.pad(input_embeddings, (0, 0, 0, padding_size), \"constant\", 0)\n",
    "        input_embeddings_projected = torch.Tensor(input_embeddings).to(device)\n",
    "\n",
    "\n",
    "        weights = learn_weights(input_embeddings)\n",
    "        # print(f'predicted weights' + str(weights))\n",
    "        # print(f'predicted weights shape' + str(weights.shape))\n",
    "        # print(f'basis shape' + str(basis.shape))\n",
    "        # print(f'input embeddings shape' + str(input_embeddings.shape))\n",
    "        # print(f'soft prompt shape' + str(soft_prompt.shape))\n",
    "        # print(f'soft prompt batch shape' + str(soft_prompt_batch.shape))\n",
    "        projected_prompt_batch = weights.unsqueeze(1).unsqueeze(2).expand_as(basis) * basis\n",
    "        projected_prompt_batch = projected_prompt_batch.sum(dim=0).unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
    "        # print(f'projected prompt batch shape' + str(projected_prompt_batch.shape))\n",
    "        # print(f'shapes of soft batch and input embeddings: {soft_prompt_batch.shape}, {input_embeddings.shape}')\n",
    "\n",
    "\n",
    "        combined_projected_embeddings = torch.cat([projected_prompt_batch, input_embeddings_projected], dim=1)\n",
    "\n",
    "        # Pass the combined embeddings through the model\n",
    "        outputs_projected = model_projected(inputs_embeds=combined_projected_embeddings, labels=labels)\n",
    " \n",
    "\n",
    "        loss_projected = outputs_projected.loss\n",
    "        epoch_loss_projected += loss_projected.item()\n",
    "        \n",
    "\n",
    "        optimizer_projected.zero_grad()\n",
    "        loss_projected.backward(retain_graph=True)\n",
    "        optimizer_projected.step()\n",
    "\n",
    "        #print(f'complete from this epoch {i}/{len(train_dataset)}', end='')\n",
    "        if _ % 200 == 0:\n",
    "          print(f'Epoch {epoch+1}/{epochs}, Batch {_}/{len(train_dataset)}')\n",
    "          print(f'Batch Indices: {[i + k for k in range(i, i+batch_size)]}')\n",
    "          print(f'Loss: {loss_projected.item()}')\n",
    "          print(f'Weights for this question: {weights} question: {batch[\"inputs_pretokenized\"]}')\n",
    "          print()\n",
    "\n",
    "    print('Validating Epoch...')\n",
    "\n",
    "    for _ in range(0, len(validation_dataset), batch_size):\n",
    "        i = random.randint(0, len(validation_dataset) - batch_size + 1 )\n",
    "        batch = validation_dataset[i:i+batch_size]\n",
    "        if len(batch['inputs_pretokenized']) != batch_size:\n",
    "          continue\n",
    "        input_ids = tokenizer(batch['inputs_pretokenized'], return_tensors='pt', padding=True, truncation=True).input_ids.to(device)\n",
    "        labels = tokenizer(batch['targets_pretokenized'], return_tensors='pt', padding=True, truncation=True).input_ids.to(device)\n",
    "\n",
    "        # Get the prompt input embeddings - same if continuous or projected\n",
    "        input_embeddings = model_projected.model.shared(input_ids)\n",
    "        padding_size = max(0, 100 - input_embeddings.shape[1])\n",
    "        input_embeddings = F.pad(input_embeddings, (0, 0, 0, padding_size), \"constant\", 0)\n",
    "        input_embeddings_projected = torch.Tensor(input_embeddings).to(device)\n",
    "\n",
    "        weights = learn_weights(input_embeddings)\n",
    "        # print(f'predicted weights' + str(weights))\n",
    "        # print(f'predicted weights shape' + str(weights.shape))\n",
    "        # print(f'basis shape' + str(basis.shape))\n",
    "        # print(f'input embeddings shape' + str(input_embeddings.shape))\n",
    "        # print(f'soft prompt shape' + str(soft_prompt.shape))\n",
    "        # print(f'soft prompt batch shape' + str(soft_prompt_batch.shape))\n",
    "        projected_prompt_batch = weights.unsqueeze(1).unsqueeze(2).expand_as(basis) * basis\n",
    "        projected_prompt_batch = projected_prompt_batch.sum(dim=0).unsqueeze(0).repeat(batch_size, 1, 1).to(device)\n",
    "        # print(f'projected prompt batch shape' + str(projected_prompt_batch.shape))\n",
    "        # print(f'shapes of soft batch and input embeddings: {soft_prompt_batch.shape}, {input_embeddings.shape}')\n",
    "\n",
    "        combined_projected_embeddings = torch.cat([projected_prompt_batch, input_embeddings_projected], dim=1)\n",
    "        outputs_projected = model_projected(inputs_embeds=combined_projected_embeddings, labels=labels)\n",
    "\n",
    "        loss_validation = outputs_projected.loss\n",
    "        epoch_loss_validation += loss_validation.item()\n",
    "\n",
    "    epoch_loss_projected /= (len(list(range(0, len(train_dataset), batch_size))))\n",
    "    epoch_loss_validation /= (len(list(range(0, len(validation_dataset), batch_size))) - 1)\n",
    "\n",
    "    print(f'Epoch Validation Loss: {epoch_loss_validation} \\n', end='')\n",
    "    print()\n",
    "\n",
    "    projected_losses.append(epoch_loss_projected)\n",
    "    validation_losses.append(epoch_loss_validation)\n",
    "\n",
    "    # Create a DataFrame with the loss values\n",
    "    n = len(projected_losses)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, n + 1), projected_losses, label='Training')\n",
    "    plt.plot(range(1, n + 1), validation_losses, label='Validation')\n",
    "    \n",
    "    plt.title(f'Normalized Loss v.s. Epoch for a Learned Linear Combination Model \\n Epochs: {epochs}, Batch Size: {batch_size}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot as a png file\n",
    "    print(f'Saveing figure...')\n",
    "    plt.savefig(f'loss_plot_epoch_{epoch+1}.png')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
