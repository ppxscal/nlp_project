{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('bigscience/P3', 'cos_e_v1.11_aligned_with_common_sense')\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained('sshleifer/distilbart-cnn-12-6')\n",
    "model = BartForConditionalGeneration.from_pretrained('sshleifer/distilbart-cnn-12-6')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn the latent space\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, latent_dim),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, input_dim),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "d = model.model.shared.embedding_dim\n",
    "batch_size = 8\n",
    "epochs = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder\n",
      "Epoch 1/10\n",
      " complete from this epoch 9736/9741 with loss 0.005565587896853685 latent shape torch.Size([5, 67, 16])Epoch 1 Loss: 7.068610766436905\n",
      "Epoch 2/10\n",
      " complete from this epoch 9736/9741 with loss 0.005535515956580639 latent shape torch.Size([5, 67, 16])Epoch 2 Loss: 6.445197727298364\n",
      "Epoch 3/10\n",
      " complete from this epoch 9736/9741 with loss 0.005521970335394144 latent shape torch.Size([5, 67, 16])Epoch 3 Loss: 6.422227872302756\n",
      "Epoch 4/10\n",
      " complete from this epoch 9736/9741 with loss 0.005511742550879717 latent shape torch.Size([5, 67, 16])Epoch 4 Loss: 6.408669068943709\n",
      "Epoch 5/10\n",
      " complete from this epoch 9736/9741 with loss 0.005474542733281851 latent shape torch.Size([5, 67, 16])Epoch 5 Loss: 6.3756560299079865\n",
      "Epoch 6/10\n",
      " complete from this epoch 9736/9741 with loss 0.005467498209327459 latent shape torch.Size([5, 67, 16])Epoch 6 Loss: 6.354588527465239\n",
      "Epoch 7/10\n",
      " complete from this epoch 9736/9741 with loss 0.005461387801915407 latent shape torch.Size([5, 67, 16])Epoch 7 Loss: 6.346662268973887\n",
      "Epoch 8/10\n",
      " complete from this epoch 9736/9741 with loss 0.00545499287545681 latent shape torch.Size([5, 67, 16]))))Epoch 8 Loss: 6.339584600878879\n",
      "Epoch 9/10\n",
      " complete from this epoch 9736/9741 with loss 0.005449572112411261 latent shape torch.Size([5, 67, 16])Epoch 9 Loss: 6.332990693859756\n",
      "Epoch 10/10\n",
      " complete from this epoch 9736/9741 with loss 0.005445488728582859 latent shape torch.Size([5, 67, 16])Epoch 10 Loss: 6.328012203099206\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder(d, latent_dim).to(device)\n",
    "autoencoder_optimizer = AdamW(autoencoder.parameters())\n",
    "\n",
    "print('Training Autoencoder')\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    for i in range(0, len(train_dataset), batch_size):\n",
    "        batch = train_dataset[i:i+batch_size]\n",
    "        input_ids = tokenizer(batch['inputs_pretokenized'], return_tensors='pt', padding=True, truncation=True).input_ids\n",
    "        input_embeddings = model.model.shared(input_ids.to(device))\n",
    "        latent_representations, reconstructed_embeddings = autoencoder(input_embeddings)\n",
    "        autoencoder_loss = torch.mean((reconstructed_embeddings - input_embeddings) ** 2)\n",
    "        print(f'\\r complete from this epoch {i}/{len(train_dataset)} with loss {autoencoder_loss} latent shape {latent_representations.shape}', end='')\n",
    "        epoch_loss += autoencoder_loss.item()\n",
    "        autoencoder_loss.backward()\n",
    "        autoencoder_optimizer.step()\n",
    "        autoencoder_optimizer.zero_grad()\n",
    "    print(f'Epoch {epoch + 1} Loss: {epoch_loss}')  # print average loss per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[[-0.0369,  0.0782,  0.1621,  ...,  0.1831,  0.0589, -0.0659],\n",
      "         [ 0.0068, -0.0898, -0.0970,  ...,  0.0197, -0.0449,  0.0517],\n",
      "         [-0.0511,  0.1375,  0.0367,  ...,  0.0351,  0.0063, -0.1656],\n",
      "         ...,\n",
      "         [ 0.0224, -0.0013, -0.0172,  ..., -0.0598, -0.0188, -0.0996],\n",
      "         [-0.0130, -0.0108, -0.0355,  ...,  0.0019, -0.0334,  0.0082],\n",
      "         [-0.0471,  0.4563, -0.0644,  ...,  0.1069,  0.0339,  0.0493]]],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward0>)\n",
      "Latent Representation: tensor([[[0.0000e+00, 0.0000e+00, 6.1153e-01,  ..., 1.3335e+00,\n",
      "          2.9484e+00, 1.0124e+00],\n",
      "         [2.8248e-01, 1.4828e-02, 4.3686e-01,  ..., 3.9212e-02,\n",
      "          1.1129e-01, 1.1596e+00],\n",
      "         [1.2981e+00, 0.0000e+00, 1.2213e+00,  ..., 1.2976e+00,\n",
      "          1.3611e+00, 9.3695e-01],\n",
      "         ...,\n",
      "         [3.4810e-01, 8.0616e-02, 5.8862e-01,  ..., 1.2121e-01,\n",
      "          5.9638e-01, 5.7909e-01],\n",
      "         [3.3136e-01, 1.2191e-01, 3.2197e-01,  ..., 7.0938e-04,\n",
      "          4.0448e-01, 3.7037e-01],\n",
      "         [3.7376e-01, 1.2800e-05, 1.0449e+00,  ..., 7.1938e-01,\n",
      "          9.9060e-01, 3.7630e-01]]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "Reconstruction: tensor([[[0.0000, 0.0835, 0.0000,  ..., 0.0000, 0.0591, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0195, 0.0000, 0.0000],\n",
      "         [0.0000, 0.1287, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.4509, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Select a sample\n",
    "sample = train_dataset[0]\n",
    "\n",
    "# Tokenize the sample and get input embeddings\n",
    "input_ids = tokenizer(sample['inputs_pretokenized'], return_tensors='pt').input_ids\n",
    "input_embeddings = model.model.shared(input_ids.to(device))\n",
    "\n",
    "# Pass the input embeddings through the autoencoder\n",
    "latent_representations, reconstructed_embeddings = autoencoder(input_embeddings)\n",
    "\n",
    "# Print the input, latent representation, and reconstruction\n",
    "print(f'Input: {input_embeddings}')\n",
    "print(f'Latent Representation: {latent_representations}')\n",
    "print(f'Reconstruction: {reconstructed_embeddings}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
